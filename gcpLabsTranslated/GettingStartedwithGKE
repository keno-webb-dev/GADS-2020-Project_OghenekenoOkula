# Google Cloud Fundamentals: Getting Started with GKE

## In this lab, you create a Google Kubernetes Engine cluster containing several containers, each containing a web server. You place a load balancer in front of the cluster and view its contents.

## Task 1: Sign in to the Google Cloud Platform (GCP) Console

## Task 2: Confirm that Container Registry API and Kubernetes Engine API are enabled

## Task 3: Start a Kubernetes Engine cluster

	1. Step 1: 
	- For convenience, place the zone that Qwiklabs assigned you to into an environment variable called MY_ZONE. At the Cloud Shell prompt, type this partial command:
	
	```
	export MY_ZONE=us-central1-a
	
	```
	
	2. Step 2:
	- Start a Kubernetes cluster managed by Kubernetes Engine. Name the cluster webfrontend and configure it to run 2 nodes:
	
	```
	gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2	
	
	```
	
	3. Step 3:
	- After the cluster is created, check your installed version of Kubernetes using the kubectl version command:
	
	```
	kubectl version
	
	```
	- Note: The gcloud container clusters create command automatically authenticated kubectl for you
	
	
## Task 4: Run and deploy a container

	1. Step 1:
	- From your Cloud Shell prompt, launch a single instance of the nginx container. (Nginx is a popular web server)
	
	```
	kubectl create deploy nginx --image=nginx:1.17.10
	
	```
	- Note: In Kubernetes, all containers run in pods. This use of the kubectl create command caused Kubernetes to create a deployment consisting of a single pod containing the nginx container.
	
	2. Step 2:
	- View the pod running the nginx container:
	
	```
	kubectl get pods
	
	```
	3. Step 3:
	- Expose the nginx container to the Internet:
	
	```
	kubectl expose deployment nginx --port 80 --type LoadBalancer
	
	```
	- Note: At this point, Kubernetes created a service and an external load balancer with a public IP address attached to it. The IP address remains the same for the life of the service. Any network traffic to that public IP address is routed to pods behind the service: in this case, the nginx pod.
	
	4. Step 4:
	- View the new service:
	
	```
	kubectl get services
	
	```
	5. Step 5:
	- Scale up the number of pods running on your service:
	
	```
	kubectl scale deployment nginx --replicas 3
	
	```
	6. Step 6:
	- Confirm that the Kubernetes has updated the number of pods:
	
	```
	kubectl get pods
		
	```
	
	7. Step 7:
	- Confirm that your external IP address has not changed:
	
	```
	kubectl get services
	
	```
	- Results: In this lab, you configured a Kubernetes cluster in Kubernetes Engine. You populated the cluster with several pods containing an application, exposed the application, and scaled the application.
	
	
